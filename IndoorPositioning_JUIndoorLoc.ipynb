{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "olPyGdHP-y2e"
   },
   "source": [
    "# Import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "n0lCfI734grC",
    "outputId": "14566d6a-7c0d-4233-ed80-f0687283528d"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "^C\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'mv' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n",
      "'rm' is not recognized as an internal or external command,\n",
      "operable program or batch file.\n"
     ]
    }
   ],
   "source": [
    "!rm -rf *\n",
    "!git clone \"https://github.com/hmda77/Ensemble-Indoor-Loc\"\n",
    "!mv -f /content/Ensemble-Indoor-Loc/JUIndoorLoc/JUIndoorLoc-Test-data.csv /content/\n",
    "!mv -f /content/Ensemble-Indoor-Loc/JUIndoorLoc/JUIndoorLoc-Training-data.csv /content/\n",
    "!rm -rf /content/Ensemble-Indoor-Loc/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z4omUYA_-1yl"
   },
   "source": [
    "#Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "AlzWAauf8fpW"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve, classification_report, auc\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "import time\n",
    "\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder , normalize\n",
    "\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DPfZUubr_BIw"
   },
   "source": [
    "# Process On Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z1nBdegW_CqO"
   },
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "tr_path = \"C://Users/Hamid/content/JUIndoorLoc-Training-data.csv\"\n",
    "ts_path = \"C://Users/Hamid/content/JUIndoorLoc-Test-data.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "9O3MtMBO8iBF",
    "outputId": "1ebd5677-5f5b-420d-9a70-4b90613e517e"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Cloning into 'Ensemble-Indoor-Loc'...\n",
      "error: RPC failed; curl 92 HTTP/2 stream 5 was not closed cleanly: CANCEL (err 8)\n",
      "error: 2708 bytes of body are still expected\n",
      "fetch-pack: unexpected disconnect while reading sideband packet\n",
      "fatal: early EOF\n",
      "fatal: fetch-pack: invalid index-pack output\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cid</th>\n",
       "      <th>AP001</th>\n",
       "      <th>AP002</th>\n",
       "      <th>AP003</th>\n",
       "      <th>AP004</th>\n",
       "      <th>AP005</th>\n",
       "      <th>AP006</th>\n",
       "      <th>AP007</th>\n",
       "      <th>AP008</th>\n",
       "      <th>AP009</th>\n",
       "      <th>...</th>\n",
       "      <th>AP167</th>\n",
       "      <th>AP168</th>\n",
       "      <th>AP169</th>\n",
       "      <th>AP170</th>\n",
       "      <th>AP171</th>\n",
       "      <th>AP172</th>\n",
       "      <th>Rs</th>\n",
       "      <th>Hpr</th>\n",
       "      <th>Did</th>\n",
       "      <th>Ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L4-40-1</td>\n",
       "      <td>-84</td>\n",
       "      <td>-80</td>\n",
       "      <td>-71</td>\n",
       "      <td>-58</td>\n",
       "      <td>-110</td>\n",
       "      <td>-72</td>\n",
       "      <td>-71</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>1469870570949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L4-40-1</td>\n",
       "      <td>-84</td>\n",
       "      <td>-79</td>\n",
       "      <td>-71</td>\n",
       "      <td>-58</td>\n",
       "      <td>-110</td>\n",
       "      <td>-72</td>\n",
       "      <td>-71</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>1470047205646</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L4-40-1</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-70</td>\n",
       "      <td>-56</td>\n",
       "      <td>-110</td>\n",
       "      <td>-69</td>\n",
       "      <td>-68</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>1469870932338</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L4-40-1</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-70</td>\n",
       "      <td>-53</td>\n",
       "      <td>-110</td>\n",
       "      <td>-69</td>\n",
       "      <td>-68</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>1470047629440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L4-37-2</td>\n",
       "      <td>-84</td>\n",
       "      <td>-82</td>\n",
       "      <td>-75</td>\n",
       "      <td>-65</td>\n",
       "      <td>-110</td>\n",
       "      <td>-73</td>\n",
       "      <td>-75</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>D4</td>\n",
       "      <td>1469876622694</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Cid  AP001  AP002  AP003  AP004  AP005  AP006  AP007  AP008  AP009  \\\n",
       "0  L4-40-1    -84    -80    -71    -58   -110    -72    -71   -110   -110   \n",
       "1  L4-40-1    -84    -79    -71    -58   -110    -72    -71   -110   -110   \n",
       "2  L4-40-1   -110   -110    -70    -56   -110    -69    -68   -110   -110   \n",
       "3  L4-40-1   -110   -110    -70    -53   -110    -69    -68   -110   -110   \n",
       "4  L4-37-2    -84    -82    -75    -65   -110    -73    -75   -110   -110   \n",
       "\n",
       "   ...  AP167  AP168  AP169  AP170  AP171  AP172  Rs  Hpr  Did             Ts  \n",
       "0  ...   -110   -110   -110   -110   -110   -110   0    1   D4  1469870570949  \n",
       "1  ...   -110   -110   -110   -110   -110   -110   0    1   D4  1470047205646  \n",
       "2  ...   -110   -110   -110   -110   -110   -110   0    1   D4  1469870932338  \n",
       "3  ...   -110   -110   -110   -110   -110   -110   0    1   D4  1470047629440  \n",
       "4  ...   -110   -110   -110   -110   -110   -110   0    1   D4  1469876622694  \n",
       "\n",
       "[5 rows x 177 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_train = pd.read_csv(tr_path)\n",
    "data_train.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "tio2zzHFKw5l"
   },
   "outputs": [],
   "source": [
    "data_train['Did'] = data_train['Did'].astype(str).str[1]\n",
    "data_train['Did'] = pd.to_numeric(data_train['Did'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 235
    },
    "id": "mne4I6_F819I",
    "outputId": "0c02e3f9-158e-49ac-f398-4d77d811819d"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cid</th>\n",
       "      <th>AP001</th>\n",
       "      <th>AP002</th>\n",
       "      <th>AP003</th>\n",
       "      <th>AP004</th>\n",
       "      <th>AP005</th>\n",
       "      <th>AP006</th>\n",
       "      <th>AP007</th>\n",
       "      <th>AP008</th>\n",
       "      <th>AP009</th>\n",
       "      <th>...</th>\n",
       "      <th>AP167</th>\n",
       "      <th>AP168</th>\n",
       "      <th>AP169</th>\n",
       "      <th>AP170</th>\n",
       "      <th>AP171</th>\n",
       "      <th>AP172</th>\n",
       "      <th>Rs</th>\n",
       "      <th>Hpr</th>\n",
       "      <th>Did</th>\n",
       "      <th>Ts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>L4-33-13</td>\n",
       "      <td>-77</td>\n",
       "      <td>-58</td>\n",
       "      <td>-66</td>\n",
       "      <td>-64</td>\n",
       "      <td>-92</td>\n",
       "      <td>-66</td>\n",
       "      <td>-66</td>\n",
       "      <td>-93</td>\n",
       "      <td>-93</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D2</td>\n",
       "      <td>1489813137748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>L4-33-13</td>\n",
       "      <td>-90</td>\n",
       "      <td>-58</td>\n",
       "      <td>-78</td>\n",
       "      <td>-56</td>\n",
       "      <td>-92</td>\n",
       "      <td>-74</td>\n",
       "      <td>-74</td>\n",
       "      <td>-87</td>\n",
       "      <td>-93</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D2</td>\n",
       "      <td>1489813179138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>L4-33-13</td>\n",
       "      <td>-80</td>\n",
       "      <td>-64</td>\n",
       "      <td>-78</td>\n",
       "      <td>-56</td>\n",
       "      <td>-92</td>\n",
       "      <td>-74</td>\n",
       "      <td>-74</td>\n",
       "      <td>-87</td>\n",
       "      <td>-93</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D2</td>\n",
       "      <td>1489812948443</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>L4-33-13</td>\n",
       "      <td>-72</td>\n",
       "      <td>-60</td>\n",
       "      <td>-74</td>\n",
       "      <td>-58</td>\n",
       "      <td>-93</td>\n",
       "      <td>-75</td>\n",
       "      <td>-76</td>\n",
       "      <td>-95</td>\n",
       "      <td>-93</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D2</td>\n",
       "      <td>1489812959103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>L4-33-13</td>\n",
       "      <td>-82</td>\n",
       "      <td>-56</td>\n",
       "      <td>-74</td>\n",
       "      <td>-56</td>\n",
       "      <td>-93</td>\n",
       "      <td>-71</td>\n",
       "      <td>-76</td>\n",
       "      <td>-89</td>\n",
       "      <td>-110</td>\n",
       "      <td>...</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>-110</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>D2</td>\n",
       "      <td>1489813079167</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 177 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        Cid  AP001  AP002  AP003  AP004  AP005  AP006  AP007  AP008  AP009  \\\n",
       "0  L4-33-13    -77    -58    -66    -64    -92    -66    -66    -93    -93   \n",
       "1  L4-33-13    -90    -58    -78    -56    -92    -74    -74    -87    -93   \n",
       "2  L4-33-13    -80    -64    -78    -56    -92    -74    -74    -87    -93   \n",
       "3  L4-33-13    -72    -60    -74    -58    -93    -75    -76    -95    -93   \n",
       "4  L4-33-13    -82    -56    -74    -56    -93    -71    -76    -89   -110   \n",
       "\n",
       "   ...  AP167  AP168  AP169  AP170  AP171  AP172  Rs  Hpr  Did             Ts  \n",
       "0  ...   -110   -110   -110   -110   -110   -110   0    0   D2  1489813137748  \n",
       "1  ...   -110   -110   -110   -110   -110   -110   0    0   D2  1489813179138  \n",
       "2  ...   -110   -110   -110   -110   -110   -110   0    0   D2  1489812948443  \n",
       "3  ...   -110   -110   -110   -110   -110   -110   0    0   D2  1489812959103  \n",
       "4  ...   -110   -110   -110   -110   -110   -110   0    0   D2  1489813079167  \n",
       "\n",
       "[5 rows x 177 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_test = pd.read_csv(ts_path)\n",
    "data_test.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "Dj5-ZRSfMCWu"
   },
   "outputs": [],
   "source": [
    "data_test['Did'] = data_test['Did'].astype(str).str[1]\n",
    "data_test['Did'] = pd.to_numeric(data_test['Did'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ui7TGJEgg2uh"
   },
   "source": [
    "# Training Base Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "uLIv8Xfhg6Gp"
   },
   "outputs": [],
   "source": [
    "def TrainingBaseModel(clf, DATA_TRAIN, f):\n",
    "  b = 0\n",
    "  TR = {} #Whole Train Set 1...b\n",
    "  OPCV = {} #KFOLD Results 1....b\n",
    "  for g in range(1,f+1):\n",
    "    for h in range(1,f+1):\n",
    "      if not (h==g) and (h>g):\n",
    "        # make a Train sets\n",
    "        TR[\"{},{}\".format(g,h)] = DATA_TRAIN.loc[(DATA_TRAIN['Did'] == g) | (DATA_TRAIN['Did'] == h)]\n",
    "\n",
    "        #make X_train from Tr\n",
    "        XTR = TR[\"{},{}\".format(g,h)].loc[:, (TR[\"{},{}\".format(g,h)].columns != 'Ts') & (TR[\"{},{}\".format(g,h)].columns != 'Cid')]\n",
    "        # XTrain_dummies = pd.get_dummies(XTR, columns = ['Did'])\n",
    "        X_train = XTR\n",
    "\n",
    "        #make Y_train from Tr (Y_true)\n",
    "        Y_train = TR[\"{},{}\".format(g,h)].Cid\n",
    "        Y_true = Y_train\n",
    "        # define 10 Fold Cross Validation\n",
    "        cv = KFold(n_splits=10, random_state=1, shuffle=True)\n",
    "\n",
    "        #make model\n",
    "        c = clf\n",
    "        # Label of Train set\n",
    "        b = b + 1\n",
    "\n",
    "        # Prediction Y_pred\n",
    "        Y_pred = cross_val_predict(c, X_train, Y_train, cv=cv, n_jobs = 1, method = 'predict')\n",
    "\n",
    "        OPCV[b] = {}\n",
    "        OPCV[b]['actual'] = Y_true\n",
    "        OPCV[b]['predict'] = Y_pred\n",
    "\n",
    "        print(\"Tr({},{}):\".format(g,h))\n",
    "        print(\"validation accuracy: {:.2%}\".format(accuracy_score(Y_true, Y_pred)))\n",
    "        print(\"----------------------------\\n\")\n",
    "  return OPCV, b\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "PLfZU323J2L6"
   },
   "source": [
    "# Weight Determination (Algorithm 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "Ax4pvHbp5IHt"
   },
   "outputs": [],
   "source": [
    "def WeightDetermine(opcv, b):\n",
    "  T = np.empty([b])\n",
    "  for q in range(1,b+1):\n",
    "    alpha = 1\n",
    "    beta = 1\n",
    "    sigma = 0.2\n",
    "    for i in range(opcv[q]['actual'].size):\n",
    "      actl = opcv[q]['actual'].to_numpy()[i]\n",
    "      prd = (opcv[q]['predict'][i])\n",
    "      if actl == prd:\n",
    "        alpha = alpha + sigma\n",
    "      else:\n",
    "        beta = beta + sigma\n",
    "\n",
    "    un = (12*alpha*beta)/(((alpha+beta)**2)*(1+alpha+beta))\n",
    "    bl = (alpha*(1-un))/(alpha+beta)\n",
    "    T[q-1] = bl + 0.5 * un\n",
    "  sumT = np.sum(T)\n",
    "  W = T/sumT\n",
    "  return W"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "50vAHcvzIYVw"
   },
   "source": [
    "# Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "4k9cJx-xG4M4"
   },
   "outputs": [],
   "source": [
    "def Classification(clf, DATA_TRAIN, DATA_TEST, f):\n",
    "  TR = {} #Whole Train Set 1...b\n",
    "\n",
    "  # make test dataset\n",
    "  Te = DATA_TEST.loc[:, (DATA_TEST.columns != 'Ts')]\n",
    "  X_test = DATA_TEST.loc[:, (DATA_TEST.columns != 'Ts') & (DATA_TEST.columns != 'Cid')]\n",
    "  Y_test = DATA_TEST.Cid\n",
    "  OPTE = {}\n",
    "  q = 0\n",
    "  for g in range(1,f+1):\n",
    "    for h in range(1,f+1):\n",
    "      if not (h==g) and (h>g):\n",
    "        # make a Train sets\n",
    "        TR[\"{},{}\".format(g,h)] = DATA_TRAIN.loc[(DATA_TRAIN['Did'] == g) | (DATA_TRAIN['Did'] == h)]\n",
    "\n",
    "        #make X_train from Tr\n",
    "        XTR = TR[\"{},{}\".format(g,h)].loc[:, (TR[\"{},{}\".format(g,h)].columns != 'Ts') & (TR[\"{},{}\".format(g,h)].columns != 'Cid')]\n",
    "        X_train = XTR\n",
    "\n",
    "        #make Y_train from Tr\n",
    "        Y_train = TR[\"{},{}\".format(g,h)].Cid\n",
    "\n",
    "        # make model\n",
    "        c = clf\n",
    "        c.fit(X_train, Y_train)\n",
    "\n",
    "\n",
    "        # prediction\n",
    "        Y_pred = c.predict(X_test)\n",
    "\n",
    "        q = q+1\n",
    "        OPTE[q] = {}\n",
    "        OPTE[q]['actual'] = Y_test\n",
    "        OPTE[q]['pred'] = Y_pred\n",
    "\n",
    "        print(\"Tr({},{}):\".format(g,h))\n",
    "        print(\"Test accuracy: {:.2%}\".format(accuracy_score(Y_test, Y_pred)))\n",
    "        print(\"----------------------------\\n\")\n",
    "\n",
    "  return OPTE"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "TeucUWgOauYh"
   },
   "source": [
    "# Weight Voting (Algorithm 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "Eb352DMtBnEF"
   },
   "outputs": [],
   "source": [
    "def WeightVoting(opte,DATA_TRAIN, DATA_TEST, w, b):\n",
    "  lk = DATA_TRAIN.Cid.unique()\n",
    "  o = lk.shape[0]\n",
    "  kapa_buf = []\n",
    "  for i in range(0, DATA_TEST.shape[0]):\n",
    "    P = np.zeros(o)\n",
    "    for q in range(1,b+1):\n",
    "      for k in range(1, o+1):\n",
    "        if lk[k-1] == opte[q]['pred'][i]:\n",
    "          z = 1\n",
    "        else:\n",
    "          z = 0\n",
    "        P[k-1] = P[k-1] + w[q-1] * z\n",
    "    kapa_buf.append(lk[np.argmax(P)])\n",
    "  kapa = np.array(kapa_buf, dtype=object)\n",
    "\n",
    "  return kapa\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "9IKm5ueOA-_h"
   },
   "source": [
    "## Weighted Ensemble Classifier (Algorithm 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "klKu8AAoacsE"
   },
   "outputs": [],
   "source": [
    "def WeightedEnsembleClassifier(clf, DATA_TRAIN, DATA_TEST):\n",
    "  b = 0\n",
    "  f = 4\n",
    "  W = None\n",
    "\n",
    "  if W == None:\n",
    "    print(\"<----------- Training base model ----------->\")\n",
    "    OPCV, b = TrainingBaseModel(clf, DATA_TRAIN, f)\n",
    "\n",
    "    print(\"\\n\\n<----------- Weight Determination ----------->\")\n",
    "    W = WeightDetermine(OPCV, b)\n",
    "    print(\"W is: {}\".format(W))\n",
    "      \n",
    "    print(\"\\n\\n<--------------- Classification --------------->\")\n",
    "    OPTE = Classification(clf, DATA_TRAIN, DATA_TEST, f)\n",
    "\n",
    "    start_time = time.time()  # Record the start time\n",
    "    print(\"\\n\\n<--------------- Weight Voting --------------->\")\n",
    "    KAPA = WeightVoting(OPTE,DATA_TRAIN, DATA_TEST, W, b)\n",
    "    print(\"weighted ensemble accuracy: {:.2%}\".format(accuracy_score(DATA_TEST.Cid, KAPA)))\n",
    "      \n",
    "    end_time = time.time()  # Record the end time\n",
    "    elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "    print(f\"test time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "sWb8dst-fNjj",
    "outputId": "f94638ca-acdb-4d07-fa69-71731a24e8fc"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<----------- Training base model ----------->\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "KeyboardInterrupt\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# clf = KNeighborsClassifier(n_neighbors=5)\n",
    "clf = SVC(kernel='linear',gamma='scale')\n",
    "WeightedEnsembleClassifier(clf, data_train,data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QsnjtfBVzg21",
    "outputId": "8a966791-e6a4-4c32-acd9-ce4b0bcbc620"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<----------- Training base model ----------->\n",
      "Tr(1,2):\n",
      "validation accuracy: 63.19%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,3):\n",
      "validation accuracy: 59.53%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,4):\n",
      "validation accuracy: 60.78%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,3):\n",
      "validation accuracy: 77.16%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,4):\n",
      "validation accuracy: 77.70%\n",
      "----------------------------\n",
      "\n",
      "Tr(3,4):\n",
      "validation accuracy: 93.77%\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "<----------- Weight Determination ----------->\n",
      "W is: [0.14623092 0.13777427 0.14066384 0.17854094 0.17980523 0.21698481]\n",
      "\n",
      "\n",
      "<--------------- Classification --------------->\n",
      "Tr(1,2):\n",
      "Test accuracy: 92.88%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,3):\n",
      "Test accuracy: 27.33%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,4):\n",
      "Test accuracy: 27.40%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,3):\n",
      "Test accuracy: 94.79%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,4):\n",
      "Test accuracy: 98.77%\n",
      "----------------------------\n",
      "\n",
      "Tr(3,4):\n",
      "Test accuracy: 28.08%\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "<--------------- Weight Voting --------------->\n",
      "weighted ensemble accuracy: 98.77%\n",
      "test time: 5.060406684875488\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "WeightedEnsembleClassifier(clf, data_train,data_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Combined dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing values in 'Cid' column after reset in train_df: 0\n",
      "Missing values in 'Cid' column after reset in test_df: 0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Read the training and test datasets\n",
    "data_train = pd.read_csv(tr_path)\n",
    "data_test = pd.read_csv(ts_path)\n",
    "\n",
    "# Preprocess 'Did' column\n",
    "data_train['Did'] = pd.to_numeric(data_train['Did'].astype(str).str[1])\n",
    "data_test['Did'] = pd.to_numeric(data_test['Did'].astype(str).str[1])\n",
    "\n",
    "# Concatenate the two datasets\n",
    "merged_data = pd.concat([data_train, data_test], ignore_index=True)\n",
    "\n",
    "# Separate features and labels\n",
    "X = merged_data.drop('Cid', axis=1)\n",
    "y = merged_data['Cid']\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, shuffle=True, random_state=42)\n",
    "\n",
    "# Create new DataFrames for train and test sets\n",
    "train_df = pd.DataFrame(X_train, columns=X.columns)\n",
    "train_df['Cid'] = y_train\n",
    "\n",
    "test_df = pd.DataFrame(X_test, columns=X.columns)\n",
    "test_df['Cid'] = y_test\n",
    "print(\"Missing values in 'Cid' column after reset in train_df:\", train_df['Cid'].isnull().sum())\n",
    "print(\"Missing values in 'Cid' column after reset in test_df:\", test_df['Cid'].isnull().sum())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<----------- Training base model ----------->\n",
      "Tr(1,2):\n",
      "validation accuracy: 6.08%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,3):\n",
      "validation accuracy: 8.42%\n",
      "----------------------------\n",
      "\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m clf \u001b[38;5;241m=\u001b[39m SVC()\n\u001b[1;32m----> 2\u001b[0m \u001b[43mWeightedEnsembleClassifier\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\u001b[43mtest_df\u001b[49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[11], line 8\u001b[0m, in \u001b[0;36mWeightedEnsembleClassifier\u001b[1;34m(clf, DATA_TRAIN, DATA_TEST)\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m W \u001b[38;5;241m==\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m      7\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m<----------- Training base model ----------->\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m----> 8\u001b[0m   OPCV, b \u001b[38;5;241m=\u001b[39m \u001b[43mTrainingBaseModel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mclf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mDATA_TRAIN\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     10\u001b[0m   \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m<----------- Weight Determination ----------->\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     11\u001b[0m   W \u001b[38;5;241m=\u001b[39m WeightDetermine(OPCV, b)\n",
      "Cell \u001b[1;32mIn[7], line 28\u001b[0m, in \u001b[0;36mTrainingBaseModel\u001b[1;34m(clf, DATA_TRAIN, f)\u001b[0m\n\u001b[0;32m     25\u001b[0m b \u001b[38;5;241m=\u001b[39m b \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m     27\u001b[0m \u001b[38;5;66;03m# Prediction Y_pred\u001b[39;00m\n\u001b[1;32m---> 28\u001b[0m Y_pred \u001b[38;5;241m=\u001b[39m \u001b[43mcross_val_predict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mY_train\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcv\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcv\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mn_jobs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpredict\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     30\u001b[0m OPCV[b] \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m     31\u001b[0m OPCV[b][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mactual\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m Y_true\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1033\u001b[0m, in \u001b[0;36mcross_val_predict\u001b[1;34m(estimator, X, y, groups, cv, n_jobs, verbose, fit_params, pre_dispatch, method)\u001b[0m\n\u001b[0;32m   1030\u001b[0m \u001b[38;5;66;03m# We clone the estimator to make sure that all the folds are\u001b[39;00m\n\u001b[0;32m   1031\u001b[0m \u001b[38;5;66;03m# independent, and that it is pickle-able.\u001b[39;00m\n\u001b[0;32m   1032\u001b[0m parallel \u001b[38;5;241m=\u001b[39m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs, verbose\u001b[38;5;241m=\u001b[39mverbose, pre_dispatch\u001b[38;5;241m=\u001b[39mpre_dispatch)\n\u001b[1;32m-> 1033\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mparallel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1034\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdelayed\u001b[49m\u001b[43m(\u001b[49m\u001b[43m_fit_and_predict\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   1035\u001b[0m \u001b[43m        \u001b[49m\u001b[43mclone\u001b[49m\u001b[43m(\u001b[49m\u001b[43mestimator\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mverbose\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfit_params\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmethod\u001b[49m\n\u001b[0;32m   1036\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1037\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43msplits\u001b[49m\n\u001b[0;32m   1038\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1040\u001b[0m inv_test_indices \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(test_indices), dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mint\u001b[39m)\n\u001b[0;32m   1041\u001b[0m inv_test_indices[test_indices] \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marange(\u001b[38;5;28mlen\u001b[39m(test_indices))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:65\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m     60\u001b[0m config \u001b[38;5;241m=\u001b[39m get_config()\n\u001b[0;32m     61\u001b[0m iterable_with_config \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m     62\u001b[0m     (_with_config(delayed_func, config), args, kwargs)\n\u001b[0;32m     63\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m delayed_func, args, kwargs \u001b[38;5;129;01min\u001b[39;00m iterable\n\u001b[0;32m     64\u001b[0m )\n\u001b[1;32m---> 65\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__call__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43miterable_with_config\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1863\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1861\u001b[0m     output \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_sequential_output(iterable)\n\u001b[0;32m   1862\u001b[0m     \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[1;32m-> 1863\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1865\u001b[0m \u001b[38;5;66;03m# Let's create an ID that uniquely identifies the current call. If the\u001b[39;00m\n\u001b[0;32m   1866\u001b[0m \u001b[38;5;66;03m# call is interrupted early and that the same instance is immediately\u001b[39;00m\n\u001b[0;32m   1867\u001b[0m \u001b[38;5;66;03m# re-used, this id will be used to prevent workers that were\u001b[39;00m\n\u001b[0;32m   1868\u001b[0m \u001b[38;5;66;03m# concurrently finalizing a task from the previous call to run the\u001b[39;00m\n\u001b[0;32m   1869\u001b[0m \u001b[38;5;66;03m# callback.\u001b[39;00m\n\u001b[0;32m   1870\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_lock:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\joblib\\parallel.py:1792\u001b[0m, in \u001b[0;36mParallel._get_sequential_output\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1790\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_batches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1791\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_dispatched_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m-> 1792\u001b[0m res \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1793\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_completed_tasks \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m   1794\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprint_progress()\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\utils\\parallel.py:127\u001b[0m, in \u001b[0;36m_FuncWrapper.__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    125\u001b[0m     config \u001b[38;5;241m=\u001b[39m {}\n\u001b[0;32m    126\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m config_context(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mconfig):\n\u001b[1;32m--> 127\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunction\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\model_selection\\_validation.py:1117\u001b[0m, in \u001b[0;36m_fit_and_predict\u001b[1;34m(estimator, X, y, train, test, verbose, fit_params, method)\u001b[0m\n\u001b[0;32m   1115\u001b[0m     estimator\u001b[38;5;241m.\u001b[39mfit(X_train, y_train, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mfit_params)\n\u001b[0;32m   1116\u001b[0m func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(estimator, method)\n\u001b[1;32m-> 1117\u001b[0m predictions \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX_test\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1119\u001b[0m encode \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m   1120\u001b[0m     method \u001b[38;5;129;01min\u001b[39;00m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdecision_function\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpredict_log_proba\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[0;32m   1121\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m y \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1122\u001b[0m )\n\u001b[0;32m   1124\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m encode:\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:818\u001b[0m, in \u001b[0;36mBaseSVC.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    816\u001b[0m     y \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39margmax(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdecision_function(X), axis\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n\u001b[0;32m    817\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m--> 818\u001b[0m     y \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    819\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclasses_\u001b[38;5;241m.\u001b[39mtake(np\u001b[38;5;241m.\u001b[39masarray(y, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mintp))\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:433\u001b[0m, in \u001b[0;36mBaseLibSVM.predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    431\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_validate_for_predict(X)\n\u001b[0;32m    432\u001b[0m predict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse_predict \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_sparse \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_dense_predict\n\u001b[1;32m--> 433\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mX\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m~\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\sklearn\\svm\\_base.py:452\u001b[0m, in \u001b[0;36mBaseLibSVM._dense_predict\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    444\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[0;32m    445\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mX.shape[1] = \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m should be equal to \u001b[39m\u001b[38;5;132;01m%d\u001b[39;00m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    446\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mthe number of samples at training time\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m    447\u001b[0m             \u001b[38;5;241m%\u001b[39m (X\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mshape_fit_[\u001b[38;5;241m0\u001b[39m])\n\u001b[0;32m    448\u001b[0m         )\n\u001b[0;32m    450\u001b[0m svm_type \u001b[38;5;241m=\u001b[39m LIBSVM_IMPL\u001b[38;5;241m.\u001b[39mindex(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_impl)\n\u001b[1;32m--> 452\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mlibsvm\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpredict\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    453\u001b[0m \u001b[43m    \u001b[49m\u001b[43mX\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    454\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    455\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msupport_vectors_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    456\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_n_support\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    457\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_dual_coef_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    458\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_intercept_\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    459\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probA\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    460\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_probB\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    461\u001b[0m \u001b[43m    \u001b[49m\u001b[43msvm_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msvm_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    462\u001b[0m \u001b[43m    \u001b[49m\u001b[43mkernel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mkernel\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    463\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdegree\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdegree\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    464\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcoef0\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcoef0\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    465\u001b[0m \u001b[43m    \u001b[49m\u001b[43mgamma\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gamma\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    466\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcache_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcache_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    467\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "clf = SVC()\n",
    "WeightedEnsembleClassifier(clf, train_df,test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<----------- Training base model ----------->\n",
      "Tr(1,2):\n",
      "validation accuracy: 57.08%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,3):\n",
      "validation accuracy: 56.86%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,4):\n",
      "validation accuracy: 54.86%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,3):\n",
      "validation accuracy: 69.72%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,4):\n",
      "validation accuracy: 70.21%\n",
      "----------------------------\n",
      "\n",
      "Tr(3,4):\n",
      "validation accuracy: 85.80%\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "<----------- Weight Determination ----------->\n",
      "W is: [0.14471071 0.14413454 0.13909281 0.17670264 0.17794054 0.21741875]\n",
      "\n",
      "\n",
      "<--------------- Classification --------------->\n",
      "Tr(1,2):\n",
      "Test accuracy: 37.83%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,3):\n",
      "Test accuracy: 51.33%\n",
      "----------------------------\n",
      "\n",
      "Tr(1,4):\n",
      "Test accuracy: 50.27%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,3):\n",
      "Test accuracy: 68.34%\n",
      "----------------------------\n",
      "\n",
      "Tr(2,4):\n",
      "Test accuracy: 67.51%\n",
      "----------------------------\n",
      "\n",
      "Tr(3,4):\n",
      "Test accuracy: 53.74%\n",
      "----------------------------\n",
      "\n",
      "\n",
      "\n",
      "<--------------- Weight Voting --------------->\n",
      "weighted ensemble accuracy: 65.01%\n",
      "test time: 41.92361664772034\n"
     ]
    }
   ],
   "source": [
    "clf = KNeighborsClassifier(n_neighbors=5)\n",
    "WeightedEnsembleClassifier(clf, train_df.drop('Ts', axis=1),test_df.drop('Ts', axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, recall_score, f1_score, confusion_matrix, precision_score, roc_curve, roc_auc_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import OrdinalEncoder , normalize\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.model_selection import cross_validate\n",
    "\n",
    "\n",
    "import time\n",
    "from tqdm import tqdm\n",
    "\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score, cross_val_predict\n",
    "\n",
    "from matplotlib import pyplot\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train_df.drop('Cid', axis=1)\n",
    "X_train = X_train.drop('Ts', axis=1)\n",
    "y_train_encode = train_df['Cid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 24.854449033737183\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "# Create RandomForest model with specified hyperparameters\n",
    "base_estimator = DecisionTreeClassifier(max_depth=49, random_state=42)\n",
    "ada_model = AdaBoostClassifier(\n",
    "    n_estimators=9,\n",
    "    estimator=base_estimator,\n",
    "    algorithm='SAMME',\n",
    "    random_state=42,\n",
    ")\n",
    "ada_model.fit(X_train, y_train_encode)\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "print(f\"train time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = test_df.drop('Cid', axis=1)\n",
    "X_test = X_test.drop('Ts', axis=1)\n",
    "y_test = test_df['Cid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time: 1.6259551048278809\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "y_pred = ada_model.predict(X_test)\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "print(f\"test time: {elapsed_time}\")\n",
    "\n",
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        L4-34-8\n",
       "1        L4-18-1\n",
       "2        L4-29-7\n",
       "3        L4-19-3\n",
       "4        L4-26-4\n",
       "          ...   \n",
       "5068    L4-18-11\n",
       "5069    L4-18-11\n",
       "5070     L4-24-4\n",
       "5071     L4-19-3\n",
       "5072    L4-33-21\n",
       "Length: 5073, dtype: object"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.954661935738222"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = data_train.drop('Cid', axis=1)\n",
    "X_train = X_train.drop('Ts', axis=1)\n",
    "y_train_encode = data_train['Cid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train time: 2.4232442378997803\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "# Create RandomForest model with specified hyperparameters\n",
    "base_estimator = DecisionTreeClassifier(max_depth=38, random_state=42)\n",
    "ada_model = RandomForestClassifier(\n",
    "    n_estimators=25,\n",
    "    max_depth=38,\n",
    "    random_state=42,\n",
    "    min_samples_split=2,\n",
    "    n_jobs=-1  # Utilize all available CPU cores\n",
    ")\n",
    "ada_model.fit(X_train, y_train_encode)\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "print(f\"train time: {elapsed_time}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = data_test.drop('Cid', axis=1)\n",
    "X_test = X_test.drop('Ts', axis=1)\n",
    "y_test = data_test['Cid']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test time: 0.17419028282165527\n"
     ]
    }
   ],
   "source": [
    "# Make predictions on the test set\n",
    "start_time = time.time()  # Record the start time\n",
    "\n",
    "y_pred = ada_model.predict(X_test)\n",
    "\n",
    "end_time = time.time()  # Record the end time\n",
    "elapsed_time = end_time - start_time  # Calculate elapsed time\n",
    "print(f\"test time: {elapsed_time}\")\n",
    "\n",
    "y_pred = pd.Series(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9910958904109589"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, y_pred)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
